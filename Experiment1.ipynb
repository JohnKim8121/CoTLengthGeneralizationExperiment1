{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPLTYBaDfhaICe6l9DLWYbi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JohnKim8121/CoTLengthGeneralizationExperiment1/blob/main/Experiment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "P7rJVosdyk-T"
      },
      "outputs": [],
      "source": [
        "# Define the vocabulary and encoding/decoding\n",
        "import string\n",
        "import torch # Import torch here for tensor conversion\n",
        "\n",
        "# Base alphabet tokens\n",
        "alphabet = list(string.ascii_uppercase)  # ['A','B',...,'Z']\n",
        "# Special tokens\n",
        "T1_TOKEN = \"[F1]\"   # denotes ROT13\n",
        "T2_TOKEN = \"[F2]\"   # denotes POS1\n",
        "THINK_TOKEN = \"<think>\"\n",
        "ANSWER_TOKEN = \"<answer>\"\n",
        "endoftext_token = \"<|endoftext|>\"\n",
        "\n",
        "\n",
        "# Construct vocabulary list\n",
        "vocab = alphabet + [T1_TOKEN, T2_TOKEN, THINK_TOKEN, ANSWER_TOKEN,endoftext_token]\n",
        "vocab_size = len(vocab)\n",
        "token_to_id = {tok: i for i, tok in enumerate(vocab)}\n",
        "id_to_token = {i: tok for tok, i in token_to_id.items()}\n",
        "\n",
        "def encode_sequence(seq_tokens):\n",
        "    \"\"\"Encode a sequence of token strings (letters or special markers) to list of ids.\"\"\"\n",
        "    return [token_to_id[token] for token in seq_tokens]\n",
        "\n",
        "def decode_sequence(id_list):\n",
        "    \"\"\"Decode a list of token ids back to token strings.\"\"\"\n",
        "    # Convert tensor elements to integers before using as dictionary keys\n",
        "    return [id_to_token[int(i)] for i in id_list]\n",
        "\n",
        "# Transformation functions\n",
        "def apply_rot(sequence, n=13):\n",
        "    \"\"\"Apply ROT-n to a sequence of letters (list of chars).\"\"\"\n",
        "    result = []\n",
        "    for ch in sequence:\n",
        "        if ch not in token_to_id or ch not in alphabet:\n",
        "            raise ValueError(f\"Unexpected token in sequence: {ch}\")\n",
        "        # shift letter by n\n",
        "        new_idx = (ord(ch) - ord('A') + n) % 26\n",
        "        result.append(chr(ord('A') + new_idx))\n",
        "    return result\n",
        "\n",
        "def apply_pos(sequence, n=1):\n",
        "    \"\"\"Apply cyclic position shift (left rotate by n) to a sequence of letters.\"\"\"\n",
        "    l = len(sequence)\n",
        "    # left rotation by n: element at index i moves to index i-n (mod l) in the result\n",
        "    return [sequence[(i + n) % l] for i in range(l)]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiment 1 is training len 3,4,5 to test len 1 and 6."
      ],
      "metadata": {
        "id": "qlKmtse9ZMla"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Function to generate a random sequence of given length\n",
        "def random_sequence(length):\n",
        "    return [random.choice(alphabet) for _ in range(length)]\n",
        "\n",
        "# Generate training examples\n",
        "train_examples3 = []\n",
        "train_examples4 = []\n",
        "train_examples5 = []\n",
        "train_lengths = [3, 4, 5]  # in-distribution sequence lengths\n",
        "for length in train_lengths:\n",
        "    # For each length, generate a number of examples (you can adjust count for real training)\n",
        "    for _ in range(10000):  # e.g., 1000 samples per length for illustration\n",
        "        seq = random_sequence(length)\n",
        "        # Randomly decide one-step or two-step transformation\n",
        "        if random.random() < 0.5:\n",
        "            # Single-step: choose F1 or F2 randomly\n",
        "            if random.random() < 0.5:\n",
        "                # ROT13 single-step\n",
        "                prompt_tokens = seq + [T1_TOKEN, ANSWER_TOKEN]\n",
        "                result_seq = apply_rot(seq, n=13)\n",
        "            else:\n",
        "                # POS1 single-step\n",
        "                prompt_tokens = seq + [T2_TOKEN, ANSWER_TOKEN]\n",
        "                result_seq = apply_pos(seq, n=1)\n",
        "            output_tokens = result_seq  # final result only\n",
        "        else:\n",
        "            # Two-step: randomly choose combination of two transforms (allow repeats)\n",
        "            # First transformation:\n",
        "            first_is_rot = random.random() < 0.5\n",
        "            if first_is_rot:\n",
        "                interm_seq = apply_rot(seq, n=13)\n",
        "                first_token = T1_TOKEN\n",
        "            else:\n",
        "                interm_seq = apply_pos(seq, n=1)\n",
        "                first_token = T2_TOKEN\n",
        "            # Second transformation:\n",
        "            second_is_rot = random.random() < 0.5\n",
        "            if second_is_rot:\n",
        "                final_seq = apply_rot(interm_seq, n=13)\n",
        "                second_token = T1_TOKEN\n",
        "            else:\n",
        "                final_seq = apply_pos(interm_seq, n=1)\n",
        "                second_token = T2_TOKEN\n",
        "            # Prompt includes both operations then <think>\n",
        "            prompt_tokens = seq + [first_token, second_token, THINK_TOKEN]\n",
        "            # Output includes intermediate result, second op token, <answer>, then final result\n",
        "            output_tokens = interm_seq + [second_token, ANSWER_TOKEN] + final_seq\n",
        "        # Encode to token ids\n",
        "        input_ids = encode_sequence(prompt_tokens)\n",
        "        output_ids = encode_sequence(output_tokens)\n",
        "        if length == 3:\n",
        "          train_examples3.append((input_ids, output_ids))\n",
        "        elif length == 4:\n",
        "          train_examples4.append((input_ids, output_ids))\n",
        "        elif length == 5:\n",
        "          train_examples5.append((input_ids, output_ids))\n",
        "\n",
        "# Generate evaluation examples for length 1 and 6 (unseen lengths)\n",
        "test_examples_len1 = []\n",
        "test_examples_len6 = []\n",
        "for _ in range(200):  # generate some test examples\n",
        "    seq1 = random_sequence(1)\n",
        "    seq6 = random_sequence(6)\n",
        "    # We'll test on single and double ops for these lengths as well\n",
        "    # Single op for length1\n",
        "    res1 = apply_rot(seq1, 13)\n",
        "    prompt1 = seq1 + [T1_TOKEN, ANSWER_TOKEN]\n",
        "    out1 = res1\n",
        "    test_examples_len1.append((encode_sequence(prompt1), encode_sequence(out1)))\n",
        "    # Two ops for length6\n",
        "    interm6 = apply_rot(seq6, 13)\n",
        "    final6 = apply_pos(interm6, 1)\n",
        "    prompt6 = seq6 + [T1_TOKEN, T2_TOKEN, THINK_TOKEN]  # e.g., first ROT13 then POS1\n",
        "    out6 = interm6 + [T2_TOKEN, ANSWER_TOKEN] + final6\n",
        "    test_examples_len6.append((encode_sequence(prompt6), encode_sequence(out6)))\n"
      ],
      "metadata": {
        "id": "S5AwOmqSyrhP"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Example training sample (decoded):\")\n",
        "ex_in, ex_out = random.choice(train_examples3)\n",
        "print(\"Prompt:\", \" \".join(decode_sequence(ex_in)))\n",
        "print(\"Target:\", \" \".join(decode_sequence(ex_out)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MA8FmyMeytsU",
        "outputId": "b950e75b-8d96-4716-cace-aa220d6b6873"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example training sample (decoded):\n",
            "Prompt: Q G C [F2] [F1] <think>\n",
            "Target: G C Q [F1] <answer> T P D\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = 109\n",
        "print((train_examples4[i][0]), (train_examples4[i][1]))\n",
        "print(decode_sequence(train_examples4[i][0]), decode_sequence(train_examples4[i][1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDGldeC1tGtl",
        "outputId": "c9ebae06-e864-4e35-bd3c-a17afadb130a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15, 5, 4, 18, 27, 29] [5, 4, 18, 15]\n",
            "['P', 'F', 'E', 'S', '[F2]', '<answer>'] ['F', 'E', 'S', 'P']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPT2----------"
      ],
      "metadata": {
        "id": "c4C7HpxyHimD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Define the PyTorch model\n",
        "class GPTDecoderTorch(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model=32, num_heads=4, num_layers=4, d_ff=128):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        # Token embedding and positional embedding\n",
        "        self.token_emb = nn.Embedding(vocab_size, d_model)\n",
        "        self.pos_emb = nn.Parameter(torch.zeros(1, 100, d_model))  # max position 100 for example\n",
        "        # Transformer decoder layers\n",
        "        self.layers = nn.ModuleList([\n",
        "            nn.TransformerDecoderLayer(d_model, num_heads, dim_feedforward=d_ff, dropout=0.0)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "        self.norm = nn.LayerNorm(d_model)\n",
        "        self.out_proj = nn.Linear(d_model, vocab_size, bias=False)\n",
        "\n",
        "    def forward(self, x, attn_mask=None):\n",
        "        \"\"\"\n",
        "        x: Tensor of shape (batch, seq_len) of token ids.\n",
        "        attn_mask: Causal mask of shape (seq_len, seq_len) if provided.\n",
        "        \"\"\"\n",
        "        batch, seq_len = x.shape\n",
        "        # Input embeddings\n",
        "        tok_embeddings = self.token_emb(x)  # (batch, seq_len, d_model)\n",
        "        tok_embeddings = tok_embeddings + self.pos_emb[:, :seq_len, :]\n",
        "        # We need to transpose to shape (seq_len, batch, d_model) for PyTorch Transformer\n",
        "        hs = tok_embeddings.transpose(0, 1)  # (seq_len, batch, d_model)\n",
        "        # Pass through each decoder layer (as we are not using an encoder, we treat it as decoder-only)\n",
        "        for layer in self.layers:\n",
        "            hs = layer(hs, hs, tgt_mask=attn_mask)  # decoder layer with no encoder (so using tgt as both)\n",
        "        hs = self.norm(hs)\n",
        "        logits = self.out_proj(hs)  # (seq_len, batch, vocab_size)\n",
        "        return logits.transpose(0, 1)  # return to (batch, seq_len, vocab_size)"
      ],
      "metadata": {
        "id": "g32HcisD3zke"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Check this part if it is correctly done!!"
      ],
      "metadata": {
        "id": "9LW7UvDfzYRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_portion = int(len(train_examples3) * 0.85)  # 85% for training\n",
        "test_portion = int(len(train_examples3) * 0.1)    # 10% for testing\n",
        "val_portion = len(train_examples3) - train_portion - test_portion  # Remaining 5% for validation\n",
        "\n",
        "train_data3 = train_examples3[:train_portion]\n",
        "test_data3 = train_examples3[train_portion:train_portion + test_portion]\n",
        "val_data3 = train_examples3[train_portion + test_portion:]\n",
        "\n",
        "train_data4 = train_examples4[:train_portion]\n",
        "test_data4 = train_examples4[train_portion:train_portion + test_portion]\n",
        "val_data4 = train_examples4[train_portion + test_portion:]\n",
        "\n",
        "train_data5 = train_examples5[:train_portion]\n",
        "test_data5 = train_examples5[train_portion:train_portion + test_portion]\n",
        "val_data5 = train_examples5[train_portion + test_portion:]\n",
        "\n",
        "train_data = train_data3 + train_data4 + train_data5\n",
        "test_data = test_data3 + test_data4 + test_data5\n",
        "val_data = val_data3 + val_data4 + val_data5\n",
        "\n",
        "print(\"Training set length:\", len(train_data))\n",
        "print(\"Validation set length:\", len(val_data))\n",
        "print(\"Test set length:\", len(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1m64y73--TE",
        "outputId": "caa4b30f-c3a2-4739-ca7c-9cc3e39045de"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set length: 25500\n",
            "Validation set length: 1500\n",
            "Test set length: 3000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model and optimizer."
      ],
      "metadata": {
        "id": "NgCFJW--5UW6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_torch = GPTDecoderTorch(vocab_size, d_model=32, num_heads=4, num_layers=4, d_ff=4*32)\n",
        "optimizer = torch.optim.Adam(model_torch.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "GhQbCX985TPD"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.tensor([[23, 9, 25, 7, 27, 29],[0, 3, 24, 4, 26, 29]])\n",
        "targets = torch.tensor([[9, 25, 7, 27, 29, 9],[3, 24, 4, 26, 29, 13]])"
      ],
      "metadata": {
        "id": "sNgdfJdjIuAF"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    logits = model_torch(inputs)\n",
        "probas = torch.softmax(logits, dim=-1)\n",
        "print(probas.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGUusDdNEv8Z",
        "outputId": "8d1c16a7-aed2-4eea-b707-2a66b2f5afef"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 6, 31])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
        "print(\"Token IDs:\\n\", token_ids)\n",
        "\n",
        "print(f\"Targets batch 1: {decode_sequence(targets[0])}\")\n",
        "print(f\"Outputs batch 1: {decode_sequence(token_ids[0].flatten())}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Of7MbBGGIvZ1",
        "outputId": "63c97f53-5782-4814-eadf-3f6edafdc4e4"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token IDs:\n",
            " tensor([[[25],\n",
            "         [ 9],\n",
            "         [25],\n",
            "         [25],\n",
            "         [13],\n",
            "         [25]],\n",
            "\n",
            "        [[21],\n",
            "         [ 5],\n",
            "         [26],\n",
            "         [21],\n",
            "         [18],\n",
            "         [25]]])\n",
            "Targets batch 1: ['J', 'Z', 'H', '[F2]', '<answer>', 'J']\n",
            "Outputs batch 1: ['Z', 'J', 'Z', 'Z', 'N', 'Z']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Logits have shape (batch_size, num_tokens, vocab_size)\n",
        "print(\"Logits shape:\", logits.shape)\n",
        "# Targets have shape (batch_size, num_tokens)\n",
        "print(\"Targets shape:\", targets.shape)\n",
        "\n",
        "logits_flat = logits.flatten(0, 1)\n",
        "targets_flat = targets.flatten()\n",
        "\n",
        "print(\"Flattened logits:\", logits_flat.shape)\n",
        "print(\"Flattened targets:\", targets_flat.shape)\n",
        "\n",
        "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dprOdYBBMEPC",
        "outputId": "d2320751-51c7-4beb-a2cc-094475f5e28b"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logits shape: torch.Size([2, 6, 31])\n",
            "Targets shape: torch.Size([2, 6])\n",
            "Flattened logits: torch.Size([12, 31])\n",
            "Flattened targets: torch.Size([12])\n",
            "tensor(3.3696)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training dataloader"
      ],
      "metadata": {
        "id": "I0-GdL7dI7We"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this training, I'm using supervised learning"
      ],
      "metadata": {
        "id": "a7YFdENKYM7e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#train_data\n",
        "\n",
        "def collate(batch):  # batch: list of (prompt_ids, target_ids)\n",
        "    xs, ys = [], []\n",
        "    for prompt, target in batch:\n",
        "        seq = prompt + target\n",
        "        x   = seq[:-1]                 # inputs\n",
        "        y   = seq[1:]                  # labels\n",
        "        xs.append(torch.tensor(x)); ys.append(torch.tensor(y))\n",
        "    L = max(len(x) for x in xs)\n",
        "    def pad(t, padval): return torch.cat([t, torch.full((L-len(t),), padval, dtype=t.dtype)])\n",
        "    X = torch.stack([pad(t, 31) for t in xs])\n",
        "    Y = torch.stack([pad(t, 31) for t in ys])\n",
        "    return {\"input_ids\": X, \"labels\": Y}"
      ],
      "metadata": {
        "id": "yb7Liit_YJnt"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add Ending token at the end."
      ],
      "metadata": {
        "id": "Jph-kbdtwmue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_collate_draft(\n",
        "    batch,\n",
        "    pad_token_id=31,\n",
        "    device=\"cpu\"\n",
        "):\n",
        "    # Find the longest sequence in the batch\n",
        "    # and increase the max length by +1, which will add one extra\n",
        "    # padding token below\n",
        "    batch_max_length = max(len(item)+1 for item in batch)\n",
        "    # Pad and prepare inputs\n",
        "    inputs_lst = []\n",
        "\n",
        "    for item in batch:\n",
        "        new_item = item.copy()\n",
        "        # Add an <|endoftext|> token\n",
        "        new_item += [pad_token_id]\n",
        "        # Pad sequences to batch_max_length\n",
        "        padded = (\n",
        "            new_item + [pad_token_id] *\n",
        "            (batch_max_length - len(new_item))\n",
        "        )\n",
        "        # Via padded[:-1], we remove the extra padded token\n",
        "        # that has been added via the +1 setting in batch_max_length\n",
        "        # (the extra padding token will be relevant in later codes)\n",
        "        inputs = torch.tensor(padded[:-1])\n",
        "        inputs_lst.append(inputs)\n",
        "\n",
        "    # Convert list of inputs to tensor and transfer to target device\n",
        "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "    return inputs_tensor"
      ],
      "metadata": {
        "id": "tSr5J1_fyQ1B"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs= custom_collate_draft(train_data[99])\n",
        "inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKJgqwCFscRm",
        "outputId": "02546522-e0b2-4e39-9898-34f390262744"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 7,  1,  9, 26, 27, 28, 31, 31],\n",
              "        [20, 14, 22, 27, 29, 14, 22, 20]])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs= collate([train_data[99]]) # Wrap in a list to simulate a batch\n",
        "inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzNplprk29U_",
        "outputId": "4a1d7914-1315-4eeb-b40e-6a2c3b775529"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[ 7,  1,  9, 26, 27, 28, 20, 14, 22, 27, 29, 14, 22]]),\n",
              " 'labels': tensor([[ 1,  9, 26, 27, 28, 20, 14, 22, 27, 29, 14, 22, 20]])}"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits = model_torch(input_ids)                  # (B,L,V)\n",
        "loss_all = torch.nn.functional.cross_entropy(\n",
        "    logits.view(-1, logits.size(-1)), labels.view(-1), reduction=\"none\"\n",
        ")\n",
        "loss = (loss_all * loss_mask.view(-1)).sum() / loss_mask.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "wuxPS2z72JUF",
        "outputId": "84b01cb4-b8d5-4c69-f2e0-b0ac71a1cb4a"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'list' object has no attribute 'shape'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2130800679.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_torch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m                  \u001b[0;31m# (B,L,V)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m loss_all = torch.nn.functional.cross_entropy(\n\u001b[1;32m      3\u001b[0m     \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"none\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss_all\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mloss_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mloss_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1020579154.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, attn_mask)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mattn_mask\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCausal\u001b[0m \u001b[0mmask\u001b[0m \u001b[0mof\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mprovided\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \"\"\"\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;31m# Input embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mtok_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch, seq_len, d_model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question I have:\n",
        "\n",
        "the teqnique I'm using is to make this model understand the context.\n",
        "\n",
        "However, the datasets I have is answer and question which is usually trained by fine tuning\n",
        "\n",
        "Then do I pretrain this model and then finetune it to do CoT?"
      ],
      "metadata": {
        "id": "ynv7F5FrMY9z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=2, shuffle=True, drop_last=True, num_workers=0)\n",
        "\n",
        "val_loader = DataLoader(val_data, batch_size=2, shuffle=True, drop_last=True, num_workers=0)"
      ],
      "metadata": {
        "id": "HKRVJL2aI3if"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x,y = train_loader\n",
        "print(x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "ZZy45_MCLxZ0",
        "outputId": "c0a1c7f6-dffd-4f85-e5a6-196db9bd45e2"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "each element in list of batch should be of equal size",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3100581505.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    732\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    788\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    791\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Handle `CustomType` automatically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m     \"\"\"\n\u001b[0;32m--> 398\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_collate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             return [\n\u001b[0;32m--> 212\u001b[0;31m                 \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             ]  # Backwards compatibility.\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0melem_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0melem_size\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"each element in list of batch should be of equal size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# It may be accessed twice, so we use a list.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: each element in list of batch should be of equal size"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train loader:\")\n",
        "for x, y in train_loader:\n",
        "    print(x.shape, y.shape)\n",
        "\n",
        "print(\"\\nValidation loader:\")\n",
        "for x, y in val_loader:\n",
        "    print(x.shape, y.shape)"
      ],
      "metadata": {
        "id": "cyooKrYxLJl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss Function----------"
      ],
      "metadata": {
        "id": "p5zwBBKSHiL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    logits = model(input_batch)\n",
        "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
        "    return loss\n",
        "\n",
        "\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        # Reduce the number of batches to match the total number of batches in the data loader\n",
        "        # if num_batches exceeds the number of batches in the data loader\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            break\n",
        "    return total_loss / num_batches"
      ],
      "metadata": {
        "id": "gvBlzVt0HPtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"mps\")\n",
        "\n",
        "print(f\"Using {device} device.\")\n",
        "\n",
        "model_torch.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
        "\n",
        "\n",
        "torch.manual_seed(123) # For reproducibility due to the shuffling in the data loader\n",
        "\n",
        "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
        "    train_loss = calc_loss_loader(train_loader, model_torch, device)\n",
        "    val_loss = calc_loss_loader(val_loader, model_torch, device)\n",
        "\n",
        "print(\"Training loss:\", train_loss)\n",
        "print(\"Validation loss:\", val_loss)"
      ],
      "metadata": {
        "id": "7kdQCHheHuzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is training loop(fix)"
      ],
      "metadata": {
        "id": "DGmrIUgm4nZm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Utility: create causal attn mask for PyTorch (size [seq_len, seq_len])\n",
        "def generate_causal_mask(seq_len):\n",
        "    mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1)  # 1s above diagonal\n",
        "    mask = mask.masked_fill(mask == 1, float('-inf'))  # convert to -inf where mask is 1 (to block)\n",
        "    return mask  # PyTorch uses -inf for masked positions"
      ],
      "metadata": {
        "id": "Vym1Y7hdJcs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "model_torch.train()\n",
        "num_epochs = 5\n",
        "batch_size = 64\n",
        "num_samples = train_inputs_t.size(0)\n",
        "for epoch in range(1, num_epochs+1):\n",
        "    # Shuffle indices\n",
        "    indices = torch.randperm(num_samples)\n",
        "    for i in range(0, num_samples, batch_size):\n",
        "        idx = indices[i:i+batch_size]\n",
        "        batch_in = train_inputs_t[idx]\n",
        "        batch_lbl = train_labels_t[idx]\n",
        "        batch_mask = loss_masks_t[idx]\n",
        "        seq_len = batch_in.size(1)\n",
        "        # Causal mask for this sequence length\n",
        "        attn_mask = generate_causal_mask(seq_len)\n",
        "        logits = model_torch(batch_in, attn_mask=attn_mask.to(batch_in.device))\n",
        "        # Compute loss: only for output part\n",
        "        logits_flat = logits.reshape(-1, vocab_size)\n",
        "        labels_flat = batch_lbl.reshape(-1)\n",
        "        mask_flat = batch_mask.reshape(-1)\n",
        "        loss = F.cross_entropy(logits_flat, labels_flat, reduction='none')\n",
        "        loss = (loss * mask_flat).sum() / mask_flat.sum()\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f\"Epoch {epoch} done (last batch loss = {loss.item():.4f}).\")"
      ],
      "metadata": {
        "id": "4DKE_0UL4pyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test the accuracy!!"
      ],
      "metadata": {
        "id": "qk-1TPGA4x2E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_torch.eval()\n",
        "\n",
        "def greedy_decode_torch(prompt_ids, max_len):\n",
        "    generated = prompt_ids.clone()  # start with the prompt\n",
        "    for _ in range(max_len):\n",
        "        seq_len = generated.size(1)\n",
        "        attn_mask = generate_causal_mask(seq_len).to(generated.device)\n",
        "        with torch.no_grad():\n",
        "            logits = model_torch(generated, attn_mask=attn_mask)\n",
        "        next_token = int(torch.argmax(logits[0, -1]))\n",
        "        # Append next token\n",
        "        next_tok_t = torch.tensor([[next_token]], dtype=torch.long)\n",
        "        generated = torch.cat([generated, next_tok_t], dim=1)\n",
        "        if next_token == token_to_id[ANSWER_TOKEN]:\n",
        "            # Continue until after answer token to get final answer,\n",
        "            # stopping criteria could also be sequence length or a special end token if defined.\n",
        "            continue\n",
        "    # Return generated part after the prompt\n",
        "    return generated[0, prompt_ids.size(1):].tolist()\n",
        "\n",
        "# Evaluate accuracy on test sets\n",
        "for test_set, name in [(test_examples_len1, \"Length-1\"), (test_examples_len6, \"Length-6\")]:\n",
        "    correct = 0\n",
        "    total = len(test_set)\n",
        "    for inp_ids, true_out_ids in test_set:\n",
        "        inp_t = torch.tensor([inp_ids], dtype=torch.long)\n",
        "        gen_ids = greedy_decode_torch(inp_t, max_len=len(true_out_ids)+5)\n",
        "        gen_ids = gen_ids[:len(true_out_ids)]\n",
        "        if gen_ids == true_out_ids:\n",
        "            correct += 1\n",
        "    print(f\"{name} exact match accuracy: {100 * correct/total:.2f}%\")"
      ],
      "metadata": {
        "id": "v9xnetRpy4Cn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decode_sequence(test_set[1][0])"
      ],
      "metadata": {
        "id": "ktang4kzuKbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode_sequence(test_set[1][1]))\n",
        "print(test_set[1])"
      ],
      "metadata": {
        "id": "XODuzfJruUZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "greedy_decode(test_set[1][0],max_len=100)"
      ],
      "metadata": {
        "id": "nBzxi2q6rJ-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b=99\n",
        "print(decode_sequence(greedy_decode(test_set[b][0],max_len=100)))\n",
        "print(decode_sequence(test_set[b][1]))"
      ],
      "metadata": {
        "id": "aXiZ4H9iuycl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next is testing len 3, 4 and 5"
      ],
      "metadata": {
        "id": "u46TssVsahUE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_examples_len3 = []\n",
        "test_examples_len4 = []\n",
        "test_examples_len5 = []\n",
        "for _ in range(200):  # generate some test examples\n",
        "    seq3 = random_sequence(3)\n",
        "    seq4 = random_sequence(4)\n",
        "    seq5 = random_sequence(5)\n",
        "\n",
        "    # Two ops for each length\n",
        "    interm3 = apply_rot(seq3, 13)\n",
        "    final3 = apply_pos(interm3, 1)\n",
        "    prompt3 = seq3 + [T1_TOKEN, T2_TOKEN, THINK_TOKEN]  # e.g., first ROT13 then POS1\n",
        "    out3 = interm3 + [T2_TOKEN, ANSWER_TOKEN] + final3\n",
        "    test_examples_len3.append((encode_sequence(prompt3), encode_sequence(out3)))\n",
        "\n",
        "    interm4 = apply_rot(seq4, 13)\n",
        "    final4 = apply_pos(interm4, 1)\n",
        "    prompt4 = seq4 + [T1_TOKEN, T2_TOKEN, THINK_TOKEN]  # e.g., first ROT13 then POS1\n",
        "    out4 = interm4 + [T2_TOKEN, ANSWER_TOKEN] + final4\n",
        "    test_examples_len4.append((encode_sequence(prompt4), encode_sequence(out4)))\n",
        "\n",
        "    interm5 = apply_rot(seq5, 13)\n",
        "    final5 = apply_pos(interm5, 1)\n",
        "    prompt5 = seq5 + [T1_TOKEN, T2_TOKEN, THINK_TOKEN]  # e.g., first ROT13 then POS1\n",
        "    out5 = interm5 + [T2_TOKEN, ANSWER_TOKEN] + final5\n",
        "    test_examples_len5.append((encode_sequence(prompt5), encode_sequence(out5)))"
      ],
      "metadata": {
        "id": "yTymWtfkaswV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate exact match on test examples\n",
        "for test_set, name in [(test_examples_len3, \"Length-3\"), (test_examples_len4, \"Length-4\"), (test_examples_len6, \"Length-5\")]:\n",
        "    correct = 0\n",
        "    total = len(test_set)\n",
        "    for inp_ids, true_out_ids in test_set:\n",
        "        # decode until we produce as many tokens as true_out (or a bit more)\n",
        "        gen_ids = greedy_decode(inp_ids, max_len=len(true_out_ids)+5)\n",
        "        # Compare with true output\n",
        "        # Note: need to stop at the same length as true output\n",
        "        gen_ids = gen_ids[:len(true_out_ids)]\n",
        "        if gen_ids == true_out_ids:\n",
        "            correct += 1\n",
        "    print(f\"{name} exact match accuracy: {100 * correct/total:.2f}%\")"
      ],
      "metadata": {
        "id": "CRThGjLSZ7jW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OLpIgYJsd9WA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "concat = train_examples[1][0]+train_examples[1][1]\n",
        "concat\n",
        "\n",
        "concat[:-1]\n",
        "for i in range(10):\n",
        "  print(train_inputs[i],train_labels[i])\n",
        "\n",
        "for i in range(10):\n",
        "  print(decode_sequence(train_inputs[i]),decode_sequence(train_labels[i]))"
      ],
      "metadata": {
        "id": "RPeRMAw6LCSs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}